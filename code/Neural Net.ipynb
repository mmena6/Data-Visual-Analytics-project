{"cells":[{"cell_type":"code","execution_count":1,"id":"79084bf8","metadata":{"id":"79084bf8","outputId":"4e1a7dcb-e158-4652-cfc3-32906b7d00b0"},"outputs":[{"name":"stderr","output_type":"stream","text":["2023-11-30 22:09:52.994577: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"]}],"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split, GridSearchCV\n","from sklearn.metrics import mean_squared_error\n","from sklearn.ensemble import RandomForestRegressor\n","from sklearn.metrics import accuracy_score, confusion_matrix\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.preprocessing import MinMaxScaler\n","import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense\n","from tensorflow.keras.losses import MeanSquaredError"]},{"cell_type":"code","execution_count":2,"id":"b9069279","metadata":{"id":"b9069279"},"outputs":[],"source":["#Dopping useless string columns that cannot feed into the neural net\n","def drop_data2(data):\n","    data = data.drop(['statecode', 'countycode', 'fipscode', 'state', 'county', 'year','county_ranked'], axis=1)\n","\n","    # Pattern to match columns to drop\n","    pattern = r'(numerator|denominator|cihigh|cilow|other)'\n","\n","    # Use DataFrame's filter method with regex to find matching columns\n","    columns_to_drop = data.filter(regex=pattern).columns\n","\n","    # print(columns_to_drop)\n","\n","    # Drop these columns\n","    data = data.drop(columns=columns_to_drop, axis=1)\n","\n","    return data"]},{"cell_type":"code","execution_count":3,"id":"9582ecff","metadata":{"id":"9582ecff"},"outputs":[],"source":["\n","# dropping columns that are identical or mostly similar to outcome columns\n","def drop_related_outcome_cols(data):\n","    pattern = r'(v127|v002|v036|v037|v042|v001|v128|v129|v144|v145|v060|v061|v147)'\n","    columns_to_drop = data.filter(regex=pattern).columns\n","    data = data.drop(columns=columns_to_drop, axis=1)\n","    return data\n","\n"]},{"cell_type":"code","execution_count":4,"id":"eecf5d88","metadata":{"id":"eecf5d88"},"outputs":[],"source":["def std_norm(data, column_lst):\n","    data = drop_data2(data) # Assuming drop_data2 is a predefined function\n","\n","    # Standardize specified columns\n","    for i in column_lst:\n","        data[i] = StandardScaler().fit_transform(np.array(data[i]).reshape(-1, 1))\n","\n","    # Calculate the weighted sum\n","    data[\"Weighted_Normalize_Outcome\"] = - (data['v127_rawvalue'] * 5 +\n","                                            data['v002_rawvalue'] * 1 +\n","                                            data['v036_rawvalue'] * 1 +\n","                                            data['v037_rawvalue'] * 2 +\n","                                            data['v042_rawvalue'] * 1)\n","\n","    # Apply Min-Max scaling to the Weighted_Normalize_Outcome column\n","    data[\"Weighted_Normalize_Outcome\"] = MinMaxScaler().fit_transform(\n","        data[\"Weighted_Normalize_Outcome\"].values.reshape(-1, 1))\n","\n","    return data"]},{"cell_type":"code","execution_count":5,"id":"c1456156","metadata":{"id":"c1456156"},"outputs":[],"source":["#Read data csv\n","data19 = pd.read_csv(\"final_dataset19.csv\")\n","data23 = pd.read_csv(\"final_dataset23.csv\")\n"]},{"cell_type":"code","execution_count":6,"id":"adcb0008","metadata":{"id":"adcb0008"},"outputs":[],"source":["#Normalize the output features \n","outcome_list = ['v127_rawvalue','v002_rawvalue','v036_rawvalue','v037_rawvalue','v042_rawvalue']\n","\n","data19 = std_norm(data19,outcome_list)\n","\n","data23 = std_norm(data23,outcome_list)\n"]},{"cell_type":"code","execution_count":7,"id":"67366f81","metadata":{"id":"67366f81","outputId":"284ab600-4340-4cce-ca5d-1ef7a860b30f"},"outputs":[],"source":["#Refine more data\n","data19 = data19.drop(columns=outcome_list)\n","data23 = data23.drop(columns=outcome_list)\n","\n","data19 = drop_related_outcome_cols(data19)\n","data23 = drop_related_outcome_cols(data23)\n","\n"]},{"cell_type":"markdown","id":"fc826f4f","metadata":{"id":"fc826f4f"},"source":["# 2019 NN"]},{"cell_type":"code","execution_count":8,"id":"e9a916a9","metadata":{"id":"e9a916a9"},"outputs":[],"source":["#refine and standardize data in 2019\n","X = data19.drop('Weighted_Normalize_Outcome', axis=1)\n","y = data19['Weighted_Normalize_Outcome']\n","\n","scaler = StandardScaler()\n","X_scaled = scaler.fit_transform(X)"]},{"cell_type":"code","execution_count":9,"id":"b7f1b6e8","metadata":{"id":"b7f1b6e8","outputId":"31296705-1fec-4be9-ad35-d5d74ef4edba"},"outputs":[{"name":"stderr","output_type":"stream","text":["2023-11-30 22:09:54.787772: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1/50\n","55/55 [==============================] - 1s 6ms/step - loss: 0.2861 - val_loss: 0.1642\n","Epoch 2/50\n","55/55 [==============================] - 0s 3ms/step - loss: 0.0885 - val_loss: 0.1181\n","Epoch 3/50\n","55/55 [==============================] - 0s 3ms/step - loss: 0.0628 - val_loss: 0.1324\n","Epoch 4/50\n","55/55 [==============================] - 0s 2ms/step - loss: 0.0465 - val_loss: 0.1007\n","Epoch 5/50\n","55/55 [==============================] - 0s 4ms/step - loss: 0.0310 - val_loss: 0.0969\n","Epoch 6/50\n","55/55 [==============================] - 0s 3ms/step - loss: 0.0255 - val_loss: 0.0875\n","Epoch 7/50\n","55/55 [==============================] - 0s 4ms/step - loss: 0.0208 - val_loss: 0.0836\n","Epoch 8/50\n","55/55 [==============================] - 0s 4ms/step - loss: 0.0200 - val_loss: 0.0981\n","Epoch 9/50\n","55/55 [==============================] - 0s 7ms/step - loss: 0.0181 - val_loss: 0.0806\n","Epoch 10/50\n","55/55 [==============================] - 1s 11ms/step - loss: 0.0165 - val_loss: 0.0770\n","Epoch 11/50\n","55/55 [==============================] - 0s 5ms/step - loss: 0.0275 - val_loss: 0.0631\n","Epoch 12/50\n","55/55 [==============================] - 0s 4ms/step - loss: 0.0237 - val_loss: 0.0739\n","Epoch 13/50\n","55/55 [==============================] - 0s 4ms/step - loss: 0.0226 - val_loss: 0.0657\n","Epoch 14/50\n","55/55 [==============================] - 0s 4ms/step - loss: 0.0397 - val_loss: 0.0690\n","Epoch 15/50\n","55/55 [==============================] - 0s 4ms/step - loss: 0.0237 - val_loss: 0.0643\n","Epoch 16/50\n","55/55 [==============================] - 0s 6ms/step - loss: 0.0132 - val_loss: 0.0654\n","Epoch 17/50\n","55/55 [==============================] - 0s 8ms/step - loss: 0.0096 - val_loss: 0.0647\n","Epoch 18/50\n","55/55 [==============================] - 0s 7ms/step - loss: 0.0041 - val_loss: 0.0675\n","Epoch 19/50\n","55/55 [==============================] - 0s 7ms/step - loss: 0.0035 - val_loss: 0.0615\n","Epoch 20/50\n","55/55 [==============================] - 0s 7ms/step - loss: 0.0033 - val_loss: 0.0613\n","Epoch 21/50\n","55/55 [==============================] - 0s 3ms/step - loss: 0.0037 - val_loss: 0.0630\n","Epoch 22/50\n","55/55 [==============================] - 0s 2ms/step - loss: 0.0035 - val_loss: 0.0648\n","Epoch 23/50\n","55/55 [==============================] - 0s 3ms/step - loss: 0.0039 - val_loss: 0.0555\n","Epoch 24/50\n","55/55 [==============================] - 0s 4ms/step - loss: 0.0041 - val_loss: 0.0640\n","Epoch 25/50\n","55/55 [==============================] - 0s 3ms/step - loss: 0.0059 - val_loss: 0.0543\n","Epoch 26/50\n","55/55 [==============================] - 0s 4ms/step - loss: 0.0063 - val_loss: 0.0584\n","Epoch 27/50\n","55/55 [==============================] - 0s 4ms/step - loss: 0.0063 - val_loss: 0.0518\n","Epoch 28/50\n","55/55 [==============================] - 0s 5ms/step - loss: 0.0045 - val_loss: 0.0605\n","Epoch 29/50\n","55/55 [==============================] - 0s 4ms/step - loss: 0.0040 - val_loss: 0.0536\n","Epoch 30/50\n","55/55 [==============================] - 0s 3ms/step - loss: 0.0047 - val_loss: 0.0500\n","Epoch 31/50\n","55/55 [==============================] - 0s 4ms/step - loss: 0.0052 - val_loss: 0.0534\n","Epoch 32/50\n","55/55 [==============================] - 0s 4ms/step - loss: 0.0090 - val_loss: 0.0465\n","Epoch 33/50\n","55/55 [==============================] - 0s 4ms/step - loss: 0.0062 - val_loss: 0.0465\n","Epoch 34/50\n","55/55 [==============================] - 0s 4ms/step - loss: 0.0038 - val_loss: 0.0427\n","Epoch 35/50\n","55/55 [==============================] - 0s 4ms/step - loss: 0.0038 - val_loss: 0.0462\n","Epoch 36/50\n","55/55 [==============================] - 0s 3ms/step - loss: 0.0025 - val_loss: 0.0416\n","Epoch 37/50\n","55/55 [==============================] - 0s 4ms/step - loss: 0.0026 - val_loss: 0.0485\n","Epoch 38/50\n","55/55 [==============================] - 0s 4ms/step - loss: 0.0044 - val_loss: 0.0408\n","Epoch 39/50\n","55/55 [==============================] - 0s 4ms/step - loss: 0.0046 - val_loss: 0.0394\n","Epoch 40/50\n","55/55 [==============================] - 0s 4ms/step - loss: 0.0052 - val_loss: 0.0407\n","Epoch 41/50\n","55/55 [==============================] - 0s 3ms/step - loss: 0.0050 - val_loss: 0.0378\n","Epoch 42/50\n","55/55 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0408\n","Epoch 43/50\n","55/55 [==============================] - 0s 3ms/step - loss: 0.0050 - val_loss: 0.0383\n","Epoch 44/50\n","55/55 [==============================] - 0s 4ms/step - loss: 0.0037 - val_loss: 0.0414\n","Epoch 45/50\n","55/55 [==============================] - 0s 4ms/step - loss: 0.0032 - val_loss: 0.0391\n","Epoch 46/50\n","55/55 [==============================] - 0s 4ms/step - loss: 0.0026 - val_loss: 0.0400\n","Epoch 47/50\n","55/55 [==============================] - 0s 4ms/step - loss: 0.0027 - val_loss: 0.0413\n","Epoch 48/50\n","55/55 [==============================] - 0s 4ms/step - loss: 0.0031 - val_loss: 0.0336\n","Epoch 49/50\n","55/55 [==============================] - 0s 4ms/step - loss: 0.0037 - val_loss: 0.0349\n","Epoch 50/50\n","55/55 [==============================] - 0s 4ms/step - loss: 0.0035 - val_loss: 0.0301\n","30/30 [==============================] - 0s 3ms/step - loss: 0.0203\n","Mean Squared Error on Test Data: 0.0202962476760149\n"]}],"source":["# Split the data\n","X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n","\n","#Create neural network 133x64x32x1\n","model = Sequential()\n","model.add(Dense(64, input_dim=113, activation='relu'))\n","model.add(Dense(32, activation='relu'))\n","model.add(Dense(1, activation='linear'))\n","\n","# Compile the model\n","model.compile(optimizer='adam', loss=MeanSquaredError())\n","\n","# Train the model\n","model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2)\n","\n","# Evaluate the model on the test set\n","mse = model.evaluate(X_test, y_test)\n","print(f'Mean Squared Error on Test Data: {mse}')"]},{"cell_type":"markdown","id":"87c10988","metadata":{"id":"87c10988"},"source":["# 2023 NN"]},{"cell_type":"code","execution_count":10,"id":"452ab808","metadata":{"id":"452ab808"},"outputs":[],"source":["#refine and standardize data in 2019\n","X = data23.drop('Weighted_Normalize_Outcome', axis=1)\n","y = data23['Weighted_Normalize_Outcome']\n","\n","scaler = StandardScaler()\n","X_scaled = scaler.fit_transform(X)"]},{"cell_type":"code","execution_count":11,"id":"246a35cf","metadata":{"id":"246a35cf","outputId":"e8acabbc-ba43-4db3-cd3c-8e94508ca3bf"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/50\n","55/55 [==============================] - 1s 8ms/step - loss: 0.4617 - val_loss: 0.1085\n","Epoch 2/50\n","55/55 [==============================] - 0s 5ms/step - loss: 0.0681 - val_loss: 0.0665\n","Epoch 3/50\n","55/55 [==============================] - 0s 6ms/step - loss: 0.0407 - val_loss: 0.0533\n","Epoch 4/50\n","55/55 [==============================] - 0s 5ms/step - loss: 0.0277 - val_loss: 0.0444\n","Epoch 5/50\n","55/55 [==============================] - 0s 4ms/step - loss: 0.0211 - val_loss: 0.0403\n","Epoch 6/50\n","55/55 [==============================] - 0s 4ms/step - loss: 0.0164 - val_loss: 0.0366\n","Epoch 7/50\n","55/55 [==============================] - 0s 5ms/step - loss: 0.0131 - val_loss: 0.0342\n","Epoch 8/50\n","55/55 [==============================] - 0s 4ms/step - loss: 0.0108 - val_loss: 0.0325\n","Epoch 9/50\n","55/55 [==============================] - 0s 5ms/step - loss: 0.0089 - val_loss: 0.0310\n","Epoch 10/50\n","55/55 [==============================] - 0s 4ms/step - loss: 0.0075 - val_loss: 0.0304\n","Epoch 11/50\n","55/55 [==============================] - 0s 3ms/step - loss: 0.0063 - val_loss: 0.0296\n","Epoch 12/50\n","55/55 [==============================] - 0s 5ms/step - loss: 0.0056 - val_loss: 0.0287\n","Epoch 13/50\n","55/55 [==============================] - 0s 4ms/step - loss: 0.0049 - val_loss: 0.0286\n","Epoch 14/50\n","55/55 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0277\n","Epoch 15/50\n","55/55 [==============================] - 0s 4ms/step - loss: 0.0036 - val_loss: 0.0277\n","Epoch 16/50\n","55/55 [==============================] - 0s 6ms/step - loss: 0.0032 - val_loss: 0.0269\n","Epoch 17/50\n","55/55 [==============================] - 0s 4ms/step - loss: 0.0029 - val_loss: 0.0266\n","Epoch 18/50\n","55/55 [==============================] - 0s 4ms/step - loss: 0.0026 - val_loss: 0.0264\n","Epoch 19/50\n","55/55 [==============================] - 0s 4ms/step - loss: 0.0023 - val_loss: 0.0259\n","Epoch 20/50\n","55/55 [==============================] - 0s 4ms/step - loss: 0.0020 - val_loss: 0.0256\n","Epoch 21/50\n","55/55 [==============================] - 0s 4ms/step - loss: 0.0018 - val_loss: 0.0254\n","Epoch 22/50\n","55/55 [==============================] - 0s 3ms/step - loss: 0.0017 - val_loss: 0.0255\n","Epoch 23/50\n","55/55 [==============================] - 0s 4ms/step - loss: 0.0016 - val_loss: 0.0251\n","Epoch 24/50\n","55/55 [==============================] - 0s 4ms/step - loss: 0.0017 - val_loss: 0.0255\n","Epoch 25/50\n","55/55 [==============================] - 0s 6ms/step - loss: 0.0020 - val_loss: 0.0247\n","Epoch 26/50\n","55/55 [==============================] - 0s 5ms/step - loss: 0.0023 - val_loss: 0.0250\n","Epoch 27/50\n","55/55 [==============================] - 0s 6ms/step - loss: 0.0019 - val_loss: 0.0242\n","Epoch 28/50\n","55/55 [==============================] - 0s 5ms/step - loss: 0.0017 - val_loss: 0.0238\n","Epoch 29/50\n","55/55 [==============================] - 0s 5ms/step - loss: 0.0019 - val_loss: 0.0236\n","Epoch 30/50\n","55/55 [==============================] - 0s 7ms/step - loss: 0.0023 - val_loss: 0.0236\n","Epoch 31/50\n","55/55 [==============================] - 0s 7ms/step - loss: 0.0018 - val_loss: 0.0234\n","Epoch 32/50\n","55/55 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 0.0231\n","Epoch 33/50\n","55/55 [==============================] - 0s 5ms/step - loss: 8.5760e-04 - val_loss: 0.0231\n","Epoch 34/50\n","55/55 [==============================] - 0s 4ms/step - loss: 7.7326e-04 - val_loss: 0.0228\n","Epoch 35/50\n","55/55 [==============================] - 0s 4ms/step - loss: 7.8986e-04 - val_loss: 0.0226\n","Epoch 36/50\n","55/55 [==============================] - 0s 4ms/step - loss: 7.9942e-04 - val_loss: 0.0225\n","Epoch 37/50\n","55/55 [==============================] - 0s 4ms/step - loss: 5.9966e-04 - val_loss: 0.0229\n","Epoch 38/50\n","55/55 [==============================] - 0s 4ms/step - loss: 5.2336e-04 - val_loss: 0.0224\n","Epoch 39/50\n","55/55 [==============================] - 0s 4ms/step - loss: 4.7832e-04 - val_loss: 0.0228\n","Epoch 40/50\n","55/55 [==============================] - 0s 4ms/step - loss: 4.8449e-04 - val_loss: 0.0222\n","Epoch 41/50\n","55/55 [==============================] - 0s 4ms/step - loss: 5.5769e-04 - val_loss: 0.0227\n","Epoch 42/50\n","55/55 [==============================] - 0s 4ms/step - loss: 6.3235e-04 - val_loss: 0.0227\n","Epoch 43/50\n","55/55 [==============================] - 0s 4ms/step - loss: 6.5970e-04 - val_loss: 0.0228\n","Epoch 44/50\n","55/55 [==============================] - 0s 4ms/step - loss: 6.7558e-04 - val_loss: 0.0224\n","Epoch 45/50\n","55/55 [==============================] - 0s 4ms/step - loss: 6.8343e-04 - val_loss: 0.0231\n","Epoch 46/50\n","55/55 [==============================] - 0s 4ms/step - loss: 6.1842e-04 - val_loss: 0.0227\n","Epoch 47/50\n","55/55 [==============================] - 0s 6ms/step - loss: 8.1846e-04 - val_loss: 0.0225\n","Epoch 48/50\n","55/55 [==============================] - 0s 4ms/step - loss: 0.0017 - val_loss: 0.0232\n","Epoch 49/50\n","55/55 [==============================] - 0s 4ms/step - loss: 0.0018 - val_loss: 0.0224\n","Epoch 50/50\n","55/55 [==============================] - 0s 5ms/step - loss: 0.0014 - val_loss: 0.0217\n","30/30 [==============================] - 0s 2ms/step - loss: 0.0252\n","Mean Squared Error on Test Data: 0.025214705616235733\n"]}],"source":["# Split the data\n","X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n","\n","#Create neural network 144x64x32x1\n","model = Sequential()\n","model.add(Dense(64, input_dim=144, activation='relu'))\n","model.add(Dense(32, activation='relu'))\n","model.add(Dense(1, activation='linear'))\n","\n","# Compile the model\n","model.compile(optimizer='adam', loss=MeanSquaredError())\n","\n","# Train the model\n","model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2)\n","\n","# Evaluate the model on the test set\n","mse = model.evaluate(X_test, y_test)\n","print(f'Mean Squared Error on Test Data: {mse}')"]},{"cell_type":"code","execution_count":13,"id":"1fdc1e30","metadata":{"id":"1fdc1e30","outputId":"59c6e41f-5f08-43c3-e4ff-3716f67ce298"},"outputs":[{"name":"stdout","output_type":"stream","text":["1/1 [==============================] - 0s 16ms/step\n","Prediction for the single sample: 0.5949423909187317\n"]}],"source":["#Demo of picking out a single sample to show how .predict() works\n","single_sample = np.array(X_test[1],ndmin=2)\n","\n","# Use the trained model to make a prediction on the single sample\n","prediction = model.predict(single_sample)\n","\n","print(f\"Prediction for the single sample: {prediction[0][0]}\")\n"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":5}
