{"cells":[{"cell_type":"code","execution_count":null,"id":"79084bf8","metadata":{"id":"79084bf8"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split, GridSearchCV\n","from sklearn.metrics import mean_squared_error\n","from sklearn.ensemble import RandomForestRegressor\n","from sklearn.metrics import accuracy_score, confusion_matrix\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.preprocessing import MinMaxScaler\n","import tabpy_client"]},{"cell_type":"code","execution_count":null,"id":"b9069279","metadata":{"id":"b9069279"},"outputs":[],"source":["def drop_data2(data):\n","    data = data.drop(['statecode', 'countycode', 'fipscode', 'state', 'county', 'year','county_ranked'], axis=1)\n","\n","    # Pattern to match columns to drop\n","    pattern = r'(numerator|denominator|cihigh|cilow|other)'\n","\n","    # Use DataFrame's filter method with regex to find matching columns\n","    columns_to_drop = data.filter(regex=pattern).columns\n","\n","    # print(columns_to_drop)\n","\n","    # Drop these columns\n","    data = data.drop(columns=columns_to_drop, axis=1)\n","\n","    return data"]},{"cell_type":"code","execution_count":null,"id":"9582ecff","metadata":{"id":"9582ecff"},"outputs":[],"source":["def drop_related_outcome_cols(data):\n","    pattern = r'(v127|v002|v036|v037|v042|v001|v128|v129|v144|v145|v060|v061|v147)'\n","    columns_to_drop = data.filter(regex=pattern).columns\n","    data = data.drop(columns=columns_to_drop, axis=1)\n","    return data"]},{"cell_type":"code","execution_count":null,"id":"eecf5d88","metadata":{"id":"eecf5d88"},"outputs":[],"source":["from sklearn.preprocessing import StandardScaler, MinMaxScaler\n","\n","def std_norm(data, column_lst):\n","    data = drop_data2(data) # Assuming drop_data2 is a predefined function\n","\n","    # Standardize specified columns\n","    v127_rawvalue = StandardScaler().fit_transform(np.array(data['v127_rawvalue']).reshape(-1, 1))\n","    v002_rawvalue = StandardScaler().fit_transform(np.array(data['v002_rawvalue']).reshape(-1, 1))\n","    v036_rawvalue = StandardScaler().fit_transform(np.array(data['v036_rawvalue']).reshape(-1, 1))\n","    v037_rawvalue = StandardScaler().fit_transform(np.array(data['v037_rawvalue']).reshape(-1, 1))\n","    v042_rawvalue = StandardScaler().fit_transform(np.array(data['v042_rawvalue']).reshape(-1, 1))\n","\n","    # Calculate the weighted sum\n","    data[\"Weighted_Normalize_Outcome\"] = - (v127_rawvalue * 5 +\n","                                            v002_rawvalue * 1 +\n","                                            v036_rawvalue * 1 +\n","                                            v037_rawvalue * 2 +\n","                                            v042_rawvalue * 1)\n","\n","    # Apply Min-Max scaling to the Weighted_Normalize_Outcome column\n","    data[\"Weighted_Normalize_Outcome\"] = MinMaxScaler().fit_transform(\n","        data[\"Weighted_Normalize_Outcome\"].values.reshape(-1, 1))\n","\n","    return data"]},{"cell_type":"code","execution_count":null,"id":"c1456156","metadata":{"id":"c1456156"},"outputs":[],"source":["#read in data\n","data19 = pd.read_csv(\"final_dataset19.csv\")\n","data23 = pd.read_csv(\"final_dataset23.csv\")"]},{"cell_type":"code","execution_count":null,"id":"adcb0008","metadata":{"id":"adcb0008"},"outputs":[],"source":["#clean data and create output column\n","outcome_list = ['v127_rawvalue','v002_rawvalue','v036_rawvalue','v037_rawvalue','v042_rawvalue']\n","\n","data19 = std_norm(data19,outcome_list)\n","data23 = std_norm(data23,outcome_list)\n","\n","#print(data23[\"Weighted_Normalize_Outcome\"].describe())\n","#print(data19[\"Weighted_Normalize_Outcome\"].describe())\n","\n","data19 = data19.drop(columns=outcome_list)\n","data23 = data23.drop(columns=outcome_list)\n","\n","data19 = drop_related_outcome_cols(data19)\n","data23 = drop_related_outcome_cols(data23)\n","\n","#data19.columns\n","#data23.columns"]},{"cell_type":"markdown","id":"fc826f4f","metadata":{"id":"fc826f4f"},"source":["# 2019 RF"]},{"cell_type":"code","execution_count":null,"id":"e9a916a9","metadata":{"id":"e9a916a9"},"outputs":[],"source":["#pre data split\n","X = data19.drop('Weighted_Normalize_Outcome', axis=1)\n","y = data19['Weighted_Normalize_Outcome']"]},{"cell_type":"code","execution_count":null,"id":"b7f1b6e8","metadata":{"id":"b7f1b6e8","outputId":"b69bd9bd-1801-4be6-bb80-de8f159c0bc5"},"outputs":[{"name":"stdout","output_type":"stream","text":["Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"]},{"data":{"text/plain":["(0.8850023831211948,\n"," {'max_depth': None,\n","  'max_features': 'auto',\n","  'min_samples_leaf': 2,\n","  'min_samples_split': 5,\n","  'n_estimators': 100})"]},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"source":["# Split the data\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n","\n","# Creating a Random Forest Regressor with GridSearchCV for hyperparameter tuning\n","\n","param_grid = {\n","    'n_estimators': [100],  # Number of trees in the forest\n","    'max_features': ['auto'],  # Number of features to consider at every split\n","    'max_depth': [None],  # Maximum number of levels in tree\n","    'min_samples_split': [5],  # Minimum number of samples required to split a node\n","    'min_samples_leaf': [2],  # Minimum number of samples required at each leaf node\n","}\n","\n","grid_search = GridSearchCV(estimator=RandomForestRegressor(random_state=1),\n","                           param_grid=param_grid,\n","                           cv=3,\n","                           verbose=1,\n","                           n_jobs=1) #Set at 1 because it Worked for some of our group and not for others. Ideally -1.\n","\n","# Fitting the grid search to the data\n","grid_search.fit(X_train, y_train)\n","\n","# Best parameters found by grid search\n","best_params = grid_search.best_params_\n","\n","# Creating a model with the best parameters\n","best_model19 = RandomForestRegressor(**best_params, random_state=1)\n","best_model19.fit(X_train, y_train)\n","\n","# Scoring the model on the test set\n","best_score = best_model19.score(X_test, y_test)\n","best_score, best_params"]},{"cell_type":"code","execution_count":null,"id":"c1bf056e","metadata":{"id":"c1bf056e","outputId":"871c52e3-d2c8-41ef-9b86-7dec3d860032"},"outputs":[{"data":{"text/plain":["0.002456517481278696"]},"execution_count":24,"metadata":{},"output_type":"execute_result"}],"source":["# Predicting and calculating the Mean Squared Error\n","y_pred = best_model19.predict(X_test)\n","mse = mean_squared_error(y_test, y_pred)\n","mse"]},{"cell_type":"markdown","id":"c7bbb75e","metadata":{"id":"c7bbb75e"},"source":["Variable importance"]},{"cell_type":"code","execution_count":null,"id":"21c7858c","metadata":{"id":"21c7858c","outputId":"9ff68368-a803-4e84-b9d2-551c3d192518"},"outputs":[{"name":"stdout","output_type":"stream","text":["Top 15 mportant features:\n"," v024_rawvalue      0.464979\n","v009_rawvalue      0.230212\n","v063_rawvalue      0.032012\n","v049_rawvalue      0.026888\n","v014_race_white    0.022312\n","v014_rawvalue      0.019180\n","v135_rawvalue      0.017311\n","v139_rawvalue      0.016812\n","v143_rawvalue      0.015050\n","v015_rawvalue      0.010926\n","v065_rawvalue      0.008742\n","v082_rawvalue      0.008178\n","v138_rawvalue      0.006467\n","v148_rawvalue      0.005114\n","v070_rawvalue      0.004696\n","dtype: float64\n"]}],"source":["# Extract feature importances\n","feature_importances = best_model19.feature_importances_\n","\n","# Convert to a Series for easier handling\n","importances_series = pd.Series(feature_importances, index=X.columns)\n","\n","# Sort the features by importance\n","sorted_importances = importances_series.sort_values(ascending=False)\n","\n","# Get the top 10 features\n","top_features = sorted_importances[:15]\n","\n","print(\"Top 15 mportant features:\\n\", top_features)"]},{"cell_type":"markdown","id":"87c10988","metadata":{"id":"87c10988"},"source":["# 2023 RF"]},{"cell_type":"code","execution_count":null,"id":"452ab808","metadata":{"id":"452ab808"},"outputs":[],"source":["#pre data split\n","X1 = data23.drop('Weighted_Normalize_Outcome', axis=1)\n","y1 = data23['Weighted_Normalize_Outcome']"]},{"cell_type":"code","execution_count":null,"id":"246a35cf","metadata":{"id":"246a35cf","outputId":"b27944c2-08be-4728-f49e-151b11e8adfc"},"outputs":[{"name":"stdout","output_type":"stream","text":["Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"]},{"data":{"text/plain":["(0.8879558723731995,\n"," {'max_depth': None,\n","  'max_features': 'auto',\n","  'min_samples_leaf': 2,\n","  'min_samples_split': 5,\n","  'n_estimators': 100})"]},"execution_count":27,"metadata":{},"output_type":"execute_result"}],"source":["# Split the data\n","X_train1, X_test1, y_train1, y_test1 = train_test_split(X1, y1, test_size=0.3, random_state=42)\n","\n","\n","param_grid = {\n","    'n_estimators': [100],  # Number of trees in the forest\n","    'max_features': ['auto'],  # Number of features to consider at every split\n","    'max_depth': [None],  # Maximum number of levels in tree\n","    'min_samples_split': [5],  # Minimum number of samples required to split a node\n","    'min_samples_leaf': [2],  # Minimum number of samples required at each leaf node\n","}\n","\n","grid_search1 = GridSearchCV(estimator=RandomForestRegressor(random_state=1),\n","                           param_grid=param_grid,\n","                           cv=3,\n","                           verbose=1,\n","                           n_jobs=1) #Set at 1 because it Worked for some of our group and not for others. Ideally -1.\n","\n","# Fitting the grid search to the data\n","grid_search1.fit(X_train1, y_train1)\n","\n","# Best parameters found by grid search\n","best_params1 = grid_search1.best_params_\n","\n","# Creating a model with the best parameters\n","best_model23 = RandomForestRegressor(**best_params, random_state=1)\n","best_model23.fit(X_train1, y_train1)\n","\n","# Scoring the model on the test set\n","best_score1 = best_model23.score(X_test1, y_test1)\n","best_score1, best_params1"]},{"cell_type":"code","execution_count":null,"id":"1f9c578d","metadata":{"scrolled":true,"id":"1f9c578d","outputId":"3e6702ff-daf7-4981-847d-1b2ffbb2a15c"},"outputs":[{"data":{"text/plain":["0.002462806038869529"]},"execution_count":28,"metadata":{},"output_type":"execute_result"}],"source":["# Predicting and calculating the Mean Squared Error\n","y_pred1 = best_model23.predict(X_test1)\n","mse23 = mean_squared_error(y_test1, y_pred1)\n","mse23"]},{"cell_type":"code","execution_count":null,"id":"408079fb","metadata":{"id":"408079fb","outputId":"a4d3e03c-41bc-4c5b-a452-c541a4fe6596"},"outputs":[{"name":"stdout","output_type":"stream","text":["Top 15 mportant features:\n"," v070_rawvalue      0.510854\n","v024_rawvalue      0.107101\n","v063_rawvalue      0.084959\n","v139_rawvalue      0.052816\n","v143_rawvalue      0.038430\n","v135_rawvalue      0.020376\n","v015_race_white    0.012299\n","v014_race_white    0.011722\n","v014_rawvalue      0.010289\n","v148_rawvalue      0.007748\n","v009_rawvalue      0.006974\n","v011_rawvalue      0.005685\n","v135_race_white    0.005109\n","v045_rawvalue      0.003836\n","v082_rawvalue      0.003566\n","dtype: float64\n"]}],"source":["# Extract feature importances\n","feature_importances1 = best_model23.feature_importances_\n","\n","# Convert to a Series for easier handling\n","importances_series1 = pd.Series(feature_importances1, index=X1.columns)\n","\n","# Sort the features by importance\n","sorted_importances1 = importances_series1.sort_values(ascending=False)\n","\n","# Get the top 10 features\n","top_features1 = sorted_importances1[:15]\n","\n","print(\"Top 15 mportant features:\\n\", top_features1)"]},{"cell_type":"markdown","id":"76cce2e7","metadata":{"id":"76cce2e7"},"source":["# TabPy Connection & Function"]},{"cell_type":"code","execution_count":null,"id":"4c802fac","metadata":{"id":"4c802fac"},"outputs":[],"source":["# Connect to TabPy server\n","connection = tabpy_client.Client('http://localhost:9004/')"]},{"cell_type":"code","execution_count":null,"id":"92174a81","metadata":{"id":"92174a81"},"outputs":[],"source":["#load data for prediction.\n","#Needed additional loading of data used for indexing during single row prediction due to tabpy limitation with pandas.\n","\n","d19 = pd.read_csv(\"final_dataset19.csv\")\n","d23 = pd.read_csv(\"final_dataset23.csv\")\n","\n","#need to drop outcome columns\n","outcome_list = ['v127_rawvalue','v002_rawvalue','v036_rawvalue','v037_rawvalue','v042_rawvalue']\n","d19 = d19.drop(columns=outcome_list)\n","d23 = d23.drop(columns=outcome_list)\n","\n","#need to drop related columns\n","d19 = drop_related_outcome_cols(d19)\n","d23 = drop_related_outcome_cols(d23)\n","\n","#need to drop unused columns from earlier method but modified\n","d19 = d19.drop(['statecode', 'countycode', 'fipscode', 'year','county_ranked'], axis=1)\n","d23 = d23.drop(['statecode', 'countycode', 'fipscode', 'year','county_ranked'], axis=1)\n","\n","# Pattern to match columns to drop\n","pattern = r'(numerator|denominator|cihigh|cilow|other)'\n","\n","# Use DataFrame's filter method with regex to find matching columns\n","columns_to_drop = d19.filter(regex=pattern).columns\n","columns_to_drop1 = d23.filter(regex=pattern).columns\n","\n","# Drop these columns\n","d19 = d19.drop(columns=columns_to_drop, axis=1)\n","d23 = d23.drop(columns=columns_to_drop1, axis=1)\n","\n","d19ind = d19.drop(['state', 'county'], axis=1)\n","d23ind = d23.drop(['state', 'county'], axis=1)\n","#print(d19ind)\n",""]},{"cell_type":"code","execution_count":null,"id":"d555191b","metadata":{"id":"d555191b"},"outputs":[],"source":["#prediction function used for RF inputs and outputs.\n","def Prediction(P1, P2, P3, P4, P5, P6, P7, P8, state, county, model, year):\n","    if year[0] == '2019' and model[0] =='Random Forest':\n","        r19, c19 = d19.shape\n","        index = -1 #error case.\n","        #search for matching state and county\n","        for i in range(0,r19):\n","            if d19.iloc[i,0] == state[0] and d19.iloc[i,1] == county[0]:\n","                index = i\n","        if index == -1:\n","            return -1\n","        else:\n","            row=d19ind.loc[index]\n","            row.at['v014_rawvalue'] = P1[0]\n","            row.at['v024_rawvalue'] = P2[0]\n","            row.at['v009_rawvalue'] = P3[0]\n","            row.at['v135_rawvalue'] = P4[0]\n","            row.at['v139_rawvalue'] = P5[0]\n","            row.at['v063_rawvalue'] = P6[0]\n","            row.at['v070_rawvalue'] = P7[0]\n","            row.at['v049_rawvalue'] = P8[0]\n","            row = row.to_numpy()\n","            Z = best_model19.predict([row])\n","            return Z[0]\n","    elif year[0] == '2023' and model[0] =='Random Forest':\n","        r23, c23 = d23.shape\n","        index = -1\n","    #search for matching state and county\n","        for i in range(0,r23):\n","            if d23.iloc[i,0] == state[0] and d23.iloc[i,1] == county[0]:\n","                index = i\n","        #retrieve row\n","        if index ==-1:\n","            return -1\n","        else:\n","            row=d23ind.loc[index]\n","            row.at['v014_rawvalue'] = P1[0]\n","            row.at['v024_rawvalue'] = P2[0]\n","            row.at['v009_rawvalue'] = P3[0]\n","            row.at['v135_rawvalue'] = P4[0]\n","            row.at['v139_rawvalue'] = P5[0]\n","            row.at['v063_rawvalue'] = P6[0]\n","            row.at['v070_rawvalue'] = P7[0]\n","            row.at['v049_rawvalue'] = P8[0]\n","            #feed into model\n","            row = row.to_numpy()\n","            #print(row)\n","            Z = best_model23.predict([row])\n","            return Z[0]\n","    #NN Code\n","    elif year[0] == '2023' and model[0] =='Neural Network':\n","        return -1 # NN code currently unable to work due to tabpy limitation with numpy\n","    else:\n","        return -1"]},{"cell_type":"code","execution_count":null,"id":"99adade4","metadata":{"id":"99adade4"},"outputs":[],"source":["# Publish prediction function to TabPy server so it can be used from Tableau\n","connection.deploy('Prediction',\n","                  Prediction, override = True)"]},{"cell_type":"code","execution_count":null,"id":"02dcb123","metadata":{"id":"02dcb123"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.7"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}